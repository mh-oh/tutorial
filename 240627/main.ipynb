{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative models\n",
    "\n",
    "- We will implement VAE and GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torchvision as thvis\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "transform = T.ToTensor()\n",
    "\n",
    "train_dataset = thvis.datasets.MNIST(\"./data\", transform=transform, train=True, download=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset  = thvis.datasets.MNIST(\"./data\", transform=transform, train=False, download=True)\n",
    "test_dataloader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./figs/vae.png\" width = 600></center>\n",
    "\n",
    "- The encoder $f(x)$ produces mean $\\mu(x)$ and log of variance $\\log\\sigma^2(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "    self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "    self.fc_log_variance = nn.Linear (hidden_dim, latent_dim)\n",
    "    self.activation = nn.LeakyReLU(0.2)\n",
    "    self.training = True\n",
    "\n",
    "  def forward(self, x):\n",
    "    h = self.activation(self.fc1(x))\n",
    "    h = self.activation(self.fc2(h))\n",
    "    mean = self.fc_mean(h)\n",
    "    log_variance = self.fc_log_variance(h)\n",
    "    return mean, log_variance\n",
    "\n",
    "encoder = Encoder(input_dim=784, hidden_dim=400, latent_dim=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./figs/vae.png\" width = 600></center>\n",
    "\n",
    "- Given a latent encoding $z$, the decoder $g$ produces reconstructed image $\\hat{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "  def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "    self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "    self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    h = self.activation(self.fc1(x))\n",
    "    h = self.activation(self.fc2(h))\n",
    "    return th.sigmoid(self.fc3(h))\n",
    "\n",
    "decoder = Decoder(latent_dim=200, hidden_dim=400, output_dim=784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two images $x_1,x_2$ (`images`), let's sample latent encoding $z_1,z_2\\in\\mathbb{R}^{200}$ (`encodings`).\n",
    "$$\n",
    "z_i\\sim\\mathcal{N}(\\mu(x_i),\\sigma^2(x_i))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([2, 28, 28])\n",
      "2 torch.Size([2, 784])\n",
      "3 torch.Size([2, 200]) torch.Size([2, 200])\n",
      "4 torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "x1, _ = train_dataset[0]\n",
    "x2, _ = train_dataset[1]\n",
    "images = th.cat([x1, x2], axis=0)\n",
    "print(1, images.shape)\n",
    "images = images.view(-1, 784)\n",
    "print(2, images.shape)\n",
    "mean, log_variance = \"\"\" Change here \"\"\"\n",
    "print(3, mean.shape, log_variance.shape)\n",
    "stddev = \"\"\" Change here \"\"\"\n",
    "epsilon = \"\"\" Change here \"\"\"\n",
    "encodings = mean + stddev * epsilon\n",
    "print(4, encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def sample(self, mean, stddev):\n",
    "    epsilon = th.randn_like(stddev)\n",
    "    z = mean + stddev * epsilon\n",
    "    return z\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean, log_variance = self.encoder(x)\n",
    "    z = self.sample(mean, th.exp(0.5 * log_variance))\n",
    "    return self.decoder(z), mean, log_variance\n",
    "\n",
    "vae = VAE(encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE loss function is simply a sum of reconstruction loss and KL divergence term:\n",
    "$$\n",
    "\\sum_{i=1}^B \\lVert x_i - g(z_i) \\rVert_2^2 + \\mathrm{KL}( \\mathcal{N}(\\mu(x_i),\\sigma^2(x_i)) \\Vert \\mathcal{N}(0, 1) ) \\ ,\n",
    "$$\n",
    "where $B$ denotes the batch size.\n",
    "\n",
    "We provide a function to compute the KL divergence term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(mean, log_variance):\n",
    "  return - 0.5 * th.sum(1 + log_variance - mean.pow(2) - log_variance.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] loss=34657.864723\n",
      "Epoch [2/30] loss=25592.713070\n",
      "Epoch [3/30] loss=23373.347513\n",
      "Epoch [4/30] loss=22469.289118\n",
      "Epoch [5/30] loss=21948.079928\n",
      "Epoch [6/30] loss=21643.518008\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "optimizer = th.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "vae.train()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  # Monitor training loss\n",
    "  train_loss = 0.0\n",
    "\n",
    "  for batch_idx, (batch, _) in enumerate(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # The shape of `images` is (B, 1, 28, 28)\n",
    "    # We expect 784=28*28 points.\n",
    "    batch = batch.view(-1, 784)\n",
    "    # Compute reconstructed images, and Gaussian parameters.\n",
    "    batch_hat, mean, log_variance = vae(batch)\n",
    "\n",
    "    reconstruction_loss = \"\"\" Change here \"\"\"\n",
    "    kldiv = \"\"\" Change here \"\"\"\n",
    "    loss = reconstruction_loss + kldiv\n",
    "\n",
    "    # Optimize.\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update stats\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "\n",
    "  # Log training stats\n",
    "  train_loss = train_loss / len(train_dataloader)\n",
    "  print(f\"Epoch [{epoch}/{n_epochs}] loss={train_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original images vs. Reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain one batch of test images.\n",
    "images, labels = next(iter(test_dataloader))\n",
    "images_flatten = images.view(images.size(0), -1)\n",
    "images = images.numpy()\n",
    "\n",
    "# Get sample outputs\n",
    "outputs, _, _ = vae(images_flatten)\n",
    "outputs = outputs.view(batch_size, 1, 28, 28)\n",
    "outputs = outputs.detach().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, \n",
    "                         ncols=10, \n",
    "                         figsize=(20, 4))\n",
    "for images, row in zip([images, outputs], axes):\n",
    "  for img, ax in zip(images, row):\n",
    "    ax.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generating new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = th.randn(batch_size, 200)\n",
    "generated_images = \"\"\" Change here \"\"\"\n",
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def show(i):\n",
    "  ax.imshow(generated_images[i].reshape(28, 28).detach().numpy(), cmap=\"gray\")\n",
    "show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fun part is interpolating between classes, that reveals transition from a class A to another class B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_a = 5\n",
    "class_b = 6\n",
    "n_steps = 10\n",
    "\n",
    "step_size = 1.0 / n_steps\n",
    "\n",
    "for (images, labels) in train_dataloader:\n",
    "  images_a = images[labels == class_a][0]\n",
    "  images_b = images[labels == class_b][0]\n",
    "  break\n",
    "\n",
    "def compute_encoding(x):\n",
    "  mean, log_variance = vae.encoder(x)\n",
    "  return vae.sample(mean, th.exp(0.5 * log_variance))\n",
    "\n",
    "with th.no_grad():\n",
    "  encodings_a = compute_encoding(images_a.reshape(-1, 784))\n",
    "  encodings_b = compute_encoding(images_b.reshape(-1, 784))\n",
    "\n",
    "diff = encodings_b - encodings_a\n",
    "steps = th.arange(0.0, 1.0 + step_size, step_size, dtype=th.float).reshape(-1, 1)\n",
    "interpolated_encodings = encodings_a + (steps * diff)\n",
    "interpolated_images = vae.decoder(interpolated_encodings).reshape(-1, 28, 28)\n",
    "\n",
    "ncols = len(interpolated_images)\n",
    "fig, axes = plt.subplots(ncols=ncols, figsize=(2*ncols, 2))\n",
    "for i in range(ncols):\n",
    "  axes[i].imshow(interpolated_images[i].detach().numpy(), cmap=\"gray\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks\n",
    "\n",
    "<center><img src=\"./figs/gan.png\" width = 600></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "transform = T.Compose([T.ToTensor(),\n",
    "                       T.Normalize(mean=[0.5], std=[0.5])])\n",
    "train_dataset = thvis.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = thvis.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()       \n",
    "    self.fc1 = nn.Linear(input_dim, 256)\n",
    "    self.fc2 = nn.Linear(256, 512)\n",
    "    self.fc3 = nn.Linear(512, 1024)\n",
    "    self.fc4 = nn.Linear(self.fc3.out_features, output_dim)\n",
    "\n",
    "  def forward(self, x): \n",
    "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "    return th.tanh(self.fc4(x))\n",
    "\n",
    "latent_dim = 100\n",
    "G = Generator(input_dim=latent_dim, output_dim=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "  def __init__(self, input_dim):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(input_dim, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 512)\n",
    "    self.fc3 = nn.Linear(512, 256)\n",
    "    self.fc4 = nn.Linear(256, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "    x = F.dropout(x, 0.3)\n",
    "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "    x = F.dropout(x, 0.3)\n",
    "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "    x = F.dropout(x, 0.3)\n",
    "    return th.sigmoid(self.fc4(x))\n",
    "\n",
    "D = Discriminator(784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training discriminator\n",
    "\n",
    "<center><img src=\"./figs/gan_discriminator.png\" width = 600></center>\n",
    "\n",
    "We **maximize** the following objective to update the discriminator $D$:\n",
    "$$\n",
    "\\frac{1}{B}\\sum_{i=1}^B \\Big( \\log D(x_i) + \\log (1 - D(G(z_i))) \\Big) \\ ,\n",
    "$$\n",
    "where $B$ denotes the batch size, and $z_i\\sim\\mathcal{N}(0, 1)$ for each $i=1,2,\\dots,B$.\n",
    "\n",
    "- $D(x)$ is the probability of $x$ being **real**.\n",
    "- Note that we do not update $G$.\n",
    "\n",
    "It is equivalent to minimize the following loss function:\n",
    "$$\n",
    "\\frac{1}{B}\\sum_{i=1}^B \\Big( \\ell_\\texttt{BCE}(D(x_i), 1) + \\ell_\\texttt{BCE}(D(G(z_i)), 0) \\Big) \\ ,\n",
    "$$\n",
    "where $\\ell_\\texttt{BCE}(p,q)\\coloneqq -q\\log p - (1 - q)\\log (1-p)$ is the binary cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = th.optim.Adam(D.parameters(), lr=0.0002)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train_discriminator(batch):\n",
    "  # The shape of `batch` is `(B, 1, 28, 28)`\n",
    "\n",
    "  D_optimizer.zero_grad()\n",
    "\n",
    "  real_loss = \"\"\" Change here \"\"\"\n",
    "  fake_loss = \"\"\" Change here \"\"\"\n",
    "\n",
    "  loss = real_loss + fake_loss\n",
    "  loss.backward()\n",
    "  D_optimizer.step()\n",
    "      \n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training generator\n",
    "\n",
    "<center><img src=\"./figs/gan_generator.png\" width = 600></center>\n",
    "\n",
    "We **minimize** the following objective to update the generator $G$:\n",
    "$$\n",
    "\\frac{1}{B}\\sum_{i=1}^B  \\log (1 - D(G(z_i))) \\ ,\n",
    "$$\n",
    "where $B$ denotes the batch size, and $z_i\\sim\\mathcal{N}(0, 1)$ for each $i=1,2,\\dots,B$.\n",
    "\n",
    "- $D(x)$ is the probability of $x$ being **real**.\n",
    "- Note that we do not update $D$.\n",
    "\n",
    "It is equivalent to minimize the following loss function:\n",
    "$$\n",
    "\\frac{1}{B}\\sum_{i=1}^B \\ell_\\texttt{BCE}(D(G(z_i)), 1) \\ ,\n",
    "$$\n",
    "where $\\ell_\\texttt{BCE}(p,q)\\coloneqq -q\\log p - (1 - q)\\log (1-p)$ is the binary cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = th.optim.Adam(G.parameters(), lr=0.0002)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train_generator():\n",
    "\n",
    "  G_optimizer.zero_grad()\n",
    "  loss = \"\"\" Change here \"\"\"\n",
    "  loss.backward()\n",
    "  G_optimizer.step()\n",
    "      \n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We alternate training of the discriminator $D$ and the generator $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  D_losses, G_losses = [], []\n",
    "  for (batch, _) in train_dataloader:\n",
    "    D_losses.append(train_discriminator(batch))\n",
    "    G_losses.append(train_generator())\n",
    "  print(f\"Epoch [{epoch}/{n_epochs}] discriminator_loss={np.mean(D_losses):.3f}, generator_loss={np.mean(G_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(G, D):\n",
    "\n",
    "  p_real = 0.0\n",
    "  p_fake = 0.0\n",
    "  for images, _ in test_dataloader:\n",
    "    with th.no_grad():\n",
    "      p_real += (D(images.view(-1, 28 * 28))).sum().item()\n",
    "      p_fake += (D(G(th.randn(batch_size, latent_dim)))).sum().item()\n",
    "  return (p_real / len(test_dataset), \n",
    "          p_fake / len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "p_real_trace = []\n",
    "p_fake_trace = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  D_losses, G_losses = [], []\n",
    "  for (batch, _) in train_dataloader:\n",
    "    D_losses.append(train_discriminator(batch))\n",
    "    G_losses.append(train_generator())\n",
    "  print(f\"Epoch [{epoch}/{n_epochs}] discriminator_loss={np.mean(D_losses):.3f}, generator_loss={np.mean(G_losses)}\")\n",
    "\n",
    "  p_real, p_fake = evaluate(G, D)\n",
    "  p_real_trace.append(p_real)\n",
    "  p_fake_trace.append(p_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How well dose the discriminator $D$ discriminate between generated images and real images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(p_fake_trace, label=\"D(generated images)\")\n",
    "ax.plot(p_real_trace, label=\"D(real images)\")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizing generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "  z = th.randn(batch_size, latent_dim)\n",
    "  generated_images = G(z).view(-1, 1, 28, 28)\n",
    "save_image(generated_images, \"gan_generated_images.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
